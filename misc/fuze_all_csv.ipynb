{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fuze all csv.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM5Luu7n7DUt"
      },
      "source": [
        "L'objectif de ce notebook est de fusionner les différents csv des procès verbaux en un seul. Chaque ligne correspondra à un étudiant, une cours et une session (et donc une seule filièere) et aura la structure suivante :\n",
        "\n",
        "| num_etudiant | niveau | formation | id_cours |   annee   | session | note | pt_jury | code_admission | ects | annee_arrivee_fac | date_naissance | dep_naissance | ville_naissance | francais | toulousain |\n",
        "|:------------:|:------:|:---------:|:--------:|:---------:|:-------:|:----:|:-------:|:--------------:|:----:|:-----------------:|:--------------:|:-------------:|:---------------:|:--------:|:----------:|\n",
        "|   12345678   |   L2   |   Maths   | resultat | 2018/2019 |    1    |  12  |    0    |      \"ab\"      |  60  |        2017       |   01/01/1999   |      031      |      muret      |   True   |    True    |\n",
        "|   23456789   |   M1   |    SID    |  epmat1s | 2017/2018 |    1    |  13  |    0    |      \"ab\"      |  30  |        2016       |   01/01/1997   |      069      |       lyon      |   True   |    False   |\n",
        "|   34567890   |   L3   |     E     | epmat1am | 2016/2017 |    2    |   9  |    0    |      \"aj\"      |   6  |        2012       |   01/01/1990   |      132      |     londres     |   False  |    False   |\n",
        "|   12345678   |   L2   |   Maths   |  epmat1s | 2018/2019 |    1    |  11  |    0    |       \"p\"      |  30  |        2017       |   01/01/1999   |      031      |      muret      |   True   |    True    |\n",
        "\n",
        "Attention :\n",
        "\n",
        "* Un étudiant apparaitra plusieurs fois dans ce tableau\n",
        "* la colonne toulousain indique si un étudiant est né en Haute-Garonne (et donc porbablement à Toulouse ou en périférie) pas s'il est réellement né à Toulouse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxkhpE5UBwRD"
      },
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwxI_PHBB19E"
      },
      "source": [
        "On récupère les fichiers :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT-RU23v6_sn"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "data_path = \"fichiers_csv/\"\n",
        "\n",
        "PVs = [f for f in listdir(data_path) if isfile(join(data_path, f))]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50gJbxhZCOe0"
      },
      "source": [
        "Initialiser le dataframe avec les colonnes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPclN7PwCOFX"
      },
      "source": [
        "columns = [\"num_etudiant\", \"niveau\", \"formation\", \"id_cours\", \"annee\", \"session\", \"note\", \"pt_jury\", \"code_admission\", \"ects\", \"annee_arrivee_fac\", \"date_naissance\", \"dep_naissance\", \"ville_naissance\", \"francais\", \"toulousain\"]\n",
        "df = pd.DataFrame(columns=columns)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0SpXGMJ1YhX"
      },
      "source": [
        "Quelques fonctions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddIPl898IXNI"
      },
      "source": [
        "def get_infos(PV_file_name) :\n",
        "    # Récupère le niveau, la formation le numéro de session et l'année scolaire\n",
        "    # d'un PV a partir de son nom de fichier\n",
        "    file_name, extention = PV_file_name.split(\".\")\n",
        "    splited = file_name.split(\" \")\n",
        "    niveau = splited[1]\n",
        "    formation = \" \".join(splited[2:-2])\n",
        "    session, annee = splited[-2:]\n",
        "    session_num = session[1] # originellement de la forme S2, on veut juste le 2\n",
        "    annee_principale = annee.split(\"-\")[0]\n",
        "    annee_scol = f\"{annee_principale}/{int(annee_principale)+1}\"\n",
        "    return niveau, formation, session_num, annee_scol\n",
        "\n",
        "def isInt(number) :\n",
        "    # Vérifie qu'une valeur (str) est effectivement un int\n",
        "    try :\n",
        "        int(number)\n",
        "        return True\n",
        "    except ValueError :\n",
        "        return False"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwE0ujIDTQY4"
      },
      "source": [
        "On va ajouter les informations au nouveau dataframe :\n",
        "(temps d'execution sur Google Colab : ~50 minutes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVRKA-T7CGLN",
        "outputId": "e7a239b6-94e3-4c1c-de3d-4dad429dad6a"
      },
      "source": [
        "for PV in tqdm(PVs, desc=\"PVs traités \") :\n",
        "    df_PV = pd.read_csv(join(data_path, PV), delimiter=\";\")\n",
        "\n",
        "    # On indique quelles colonnes on considère comme un index\n",
        "    # (les lignes qui seront dupliquées)\n",
        "    id_cols = [\"num_etudiant\", \"identification\"]\n",
        "\n",
        "    # On indique quelles colonnes on considère comme des valeurs\n",
        "    # C'est a dire qu'on va faire fondre notre dataframe par rapport a ces \n",
        "    # colonnes. \n",
        "    # Lire https://ichi.pro/fr/comprendre-pandas-melt-pd-melt-59551147147557 \n",
        "    # pour approfondir\n",
        "    values_cols = [col_name for col_name in df_PV.columns if col_name not in id_cols]\n",
        "\n",
        "    # on fait \"fondre\" notre dataframe\n",
        "    df_melted = df_PV.melt(id_vars = id_cols, value_vars=values_cols, var_name=\"id_cours\", value_name=\"infos_notes\")\n",
        "\n",
        "    # On récupère les infomations générales du PV\n",
        "    niveau, formation, session_num, annee_scol = get_infos(PV)\n",
        "\n",
        "    for _, row in df_melted.iterrows():\n",
        "\n",
        "        # On récupère l'identification de l'étudiant\n",
        "        num_etudiant, annee_arrivee_fac, date_naissance, dep_naissance, ville_naissance, francais, toulousain = eval(row[\"identification\"])\n",
        "        \n",
        "        # On récupère l'id du cours actuel\n",
        "        id_cours = row[\"id_cours\"]\n",
        "\n",
        "        # On récupères les notes et les infos sur les résultats du cours\n",
        "        note, pt_jury, code_admission, ects, mention, annee_valid, session_valid = eval(row[\"infos_notes\"])\n",
        "            \n",
        "\n",
        "        annee_valid = f\"{annee_valid}/{int(annee_valid)+1}\" if annee_valid is not None and isInt(annee_valid) else None\n",
        "\n",
        "        # On modifie l'année is dans le PV, la date de validation est spécifiée et\n",
        "        # est différente de l'année du PV\n",
        "        annee = annee_scol if (annee_valid == annee_scol or annee_valid is None) else annee_valid\n",
        "        # On fait de même pour la session\n",
        "        session = session_num if (session_valid == session_num or session_valid is None) else session_valid\n",
        "        \n",
        "        # On créé notre nouvelle ligne pour le nouveau dataframe\n",
        "        new_row = [num_etudiant, niveau, formation, id_cours, annee, session, note, pt_jury, code_admission, ects, annee_arrivee_fac, date_naissance, dep_naissance, ville_naissance, francais, toulousain]\n",
        "        df.loc[len(df.index)] = new_row"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PVs traités : 100%|██████████| 89/89 [50:28<00:00, 34.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyzVEBPuJPU0",
        "outputId": "3e8de339-739a-42a1-c2f9-af4fa2703006"
      },
      "source": [
        "len(df)-len(df.drop_duplicates()) # Le nombre de lignes dupliquées\n",
        "# Cela survient surement car un étudiant redouble mais a validé une matière lors\n",
        "# de l'année précédente, on peut donc enlever ces lignes"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDDQCpxTLEz-"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BW5eM6YJt0-"
      },
      "source": [
        "# On elève les lignes dupliquées\n",
        "df = df.drop_duplicates()\n",
        "# On remplace les valeurs None par np.nan\n",
        "df = df.fillna(value=np.nan)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "DIdole5EKOet",
        "outputId": "28d6b778-d0b5-49ba-a623-9fb1414162ad"
      },
      "source": [
        "df"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_etudiant</th>\n",
              "      <th>niveau</th>\n",
              "      <th>formation</th>\n",
              "      <th>id_cours</th>\n",
              "      <th>annee</th>\n",
              "      <th>session</th>\n",
              "      <th>note</th>\n",
              "      <th>pt_jury</th>\n",
              "      <th>code_admission</th>\n",
              "      <th>ects</th>\n",
              "      <th>annee_arrivee_fac</th>\n",
              "      <th>date_naissance</th>\n",
              "      <th>dep_naissance</th>\n",
              "      <th>ville_naissance</th>\n",
              "      <th>francais</th>\n",
              "      <th>toulousain</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21300160</td>\n",
              "      <td>L3</td>\n",
              "      <td>E</td>\n",
              "      <td>resultat</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>def</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>06/06/1995</td>\n",
              "      <td>031</td>\n",
              "      <td>toulouse</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21005127</td>\n",
              "      <td>L3</td>\n",
              "      <td>E</td>\n",
              "      <td>resultat</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>10.425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>adm</td>\n",
              "      <td>60.0</td>\n",
              "      <td>2010</td>\n",
              "      <td>06/03/1992</td>\n",
              "      <td>031</td>\n",
              "      <td>toulouse</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21301391</td>\n",
              "      <td>L3</td>\n",
              "      <td>E</td>\n",
              "      <td>resultat</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>8.357</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aj</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>15/11/1995</td>\n",
              "      <td>032</td>\n",
              "      <td>auch</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21301392</td>\n",
              "      <td>L3</td>\n",
              "      <td>E</td>\n",
              "      <td>resultat</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2013</td>\n",
              "      <td>26/01/1994</td>\n",
              "      <td>054</td>\n",
              "      <td>nancy</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>21604149</td>\n",
              "      <td>L3</td>\n",
              "      <td>E</td>\n",
              "      <td>resultat</td>\n",
              "      <td>2016/2017</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>def</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016</td>\n",
              "      <td>05/10/1984</td>\n",
              "      <td>134</td>\n",
              "      <td>pamplona</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96764</th>\n",
              "      <td>21813431</td>\n",
              "      <td>L3</td>\n",
              "      <td>MAPI3</td>\n",
              "      <td>elmai6vm</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>1</td>\n",
              "      <td>13.000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>adm</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2018</td>\n",
              "      <td>08/05/1998</td>\n",
              "      <td>350</td>\n",
              "      <td>oujda</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96765</th>\n",
              "      <td>21813168</td>\n",
              "      <td>L3</td>\n",
              "      <td>MAPI3</td>\n",
              "      <td>elmai6vm</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>1</td>\n",
              "      <td>14.200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>adm</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2018</td>\n",
              "      <td>07/06/1997</td>\n",
              "      <td>352</td>\n",
              "      <td>bejaia</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96766</th>\n",
              "      <td>21407878</td>\n",
              "      <td>L3</td>\n",
              "      <td>MAPI3</td>\n",
              "      <td>elmai6vm</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014</td>\n",
              "      <td>26/05/1993</td>\n",
              "      <td>081</td>\n",
              "      <td>mazamet</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96767</th>\n",
              "      <td>21606663</td>\n",
              "      <td>L3</td>\n",
              "      <td>MAPI3</td>\n",
              "      <td>elmai6vm</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>def</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016</td>\n",
              "      <td>25/11/1998</td>\n",
              "      <td>065</td>\n",
              "      <td>tarbes</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96768</th>\n",
              "      <td>21607753</td>\n",
              "      <td>L3</td>\n",
              "      <td>MAPI3</td>\n",
              "      <td>elmai6vm</td>\n",
              "      <td>2018/2019</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>def</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2016</td>\n",
              "      <td>18/03/1995</td>\n",
              "      <td>216</td>\n",
              "      <td>shijiqzhuang</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96769 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      num_etudiant niveau formation  ... ville_naissance francais toulousain\n",
              "0         21300160     L3         E  ...        toulouse     True       True\n",
              "1         21005127     L3         E  ...        toulouse     True       True\n",
              "2         21301391     L3         E  ...            auch     True      False\n",
              "3         21301392     L3         E  ...           nancy     True      False\n",
              "4         21604149     L3         E  ...        pamplona    False      False\n",
              "...            ...    ...       ...  ...             ...      ...        ...\n",
              "96764     21813431     L3     MAPI3  ...           oujda    False      False\n",
              "96765     21813168     L3     MAPI3  ...          bejaia    False      False\n",
              "96766     21407878     L3     MAPI3  ...         mazamet     True      False\n",
              "96767     21606663     L3     MAPI3  ...          tarbes     True      False\n",
              "96768     21607753     L3     MAPI3  ...    shijiqzhuang    False      False\n",
              "\n",
              "[96769 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD6lBQouS-UV"
      },
      "source": [
        "### Et voila ! On a créé notre nouveau dataframe avec les infos de tous les PVs réunis\n",
        "Maintenant, on l'exporte."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aW9X0J0HlkO"
      },
      "source": [
        "df.to_csv(\"fused_PVs_long_format.csv\", index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwGCKMCkNsVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}